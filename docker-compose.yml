version: '3.7'

services:

  beargo-frontend:
    image: tonnidas/beargo-frontend
    build:
      context: frontend/React/project_react
      dockerfile: Dockerfile
      args:
        REACT_APP_API_BASE_URL: /api
    ports:
      - "80:80"
      - "443:443"
    restart: always
    volumes:
      - /etc/letsencrypt:/etc/letsencrypt:ro
    depends_on:
      - beargo-backend

  beargo-backend:
    image: tonnidas/beargo-backend
    build:
      context: backend
      dockerfile: Dockerfile
    expose:
      - "8080"
    restart: always
    depends_on:
      - beargo-db
    environment:
      SPRING_DATASOURCE_USERNAME: root
      SPRING_DATASOURCE_PASSWORD: ${BEARGO_ADMIN_PASSWORD:?}
      SPRING_DATASOURCE_URL: jdbc:mysql://beargo-db:3306/beargo
      BEARGO_ADMIN_PASSWORD: ${BEARGO_ADMIN_PASSWORD:?}
      SENDGRID_API_KEY: ${SENDGRID_API_KEY}
      KAFKA_SERVER: kafkaserver:9092

  beargo-db:
    image: mysql:5.7
    expose:
      - "3306"
    restart: always
    environment:
      MYSQL_DATABASE: beargo
      MYSQL_ROOT_PASSWORD: ${BEARGO_ADMIN_PASSWORD:?}
    volumes:
      - db-data:/var/lib/mysql

  twitter-stream-integration:
    image: tonnidas/twitter-stream-integration
    build:
      context: twitter-stream-integration
      dockerfile: Dockerfile
    environment:
      - KAFKA_SERVER=kafkaserver:9092

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.7.0
    container_name: elasticsearch
    environment:
      - node.name=elasticsearch
      - discovery.type=single-node
      - cluster.name=docker-cluster
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    ports:
      - 9300:9300
      - 9200:9200

  kibana:
    image: docker.elastic.co/kibana/kibana:7.7.0
    container_name: kibana
    environment:
      ELASTICSEARCH_URL: "http://elasticsearch:9300"
    ports:
      - 5601:5601

  logstash:
    image: docker.elastic.co/logstash/logstash:7.7.0
    container_name: logstash
    command: logstash -f /etc/logstash/conf.d/logstash.conf
    volumes:
      - ./kafka-server/config:/etc/logstash/conf.d
    ports:
      - "5000:5000"

  zookeeper:
    image: wurstmeister/zookeeper:latest
    container_name: zookeeper
    ports:
      - 2181:2181

  kafkaserver:
    image: wurstmeister/kafka:latest
    container_name: kafka
    ports:
      - 9092:9092
    environment:
      - KAFKA_ADVERTISED_HOST_NAME=kafkaserver
      - KAFKA_ADVERTISED_PORT=9092
      - KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
      - KAFKA_CREATE_TOPICS=dresses:1:1,ratings:1:1
    volumes:
      - "/var/run/docker.sock:/var/run/docker.sock"
    depends_on:
      - zookeeper

volumes:
  db-data:
